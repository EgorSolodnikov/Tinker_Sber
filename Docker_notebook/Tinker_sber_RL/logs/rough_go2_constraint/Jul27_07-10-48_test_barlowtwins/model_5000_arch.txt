Model Architecture:
ActorCriticMixedBarlowTwins(
  (priv_encoder): Identity()
  (scan_encoder): Identity()
  (history_encoder): StateHistoryEncoder(
    (activation_fn): ELU(alpha=1.0)
    (encoder): Sequential(
      (0): Linear(in_features=39, out_features=30, bias=True)
      (1): ELU(alpha=1.0)
    )
    (conv_layers): Sequential(
      (0): Conv1d(30, 20, kernel_size=(4,), stride=(2,))
      (1): ELU(alpha=1.0)
      (2): Conv1d(20, 10, kernel_size=(2,), stride=(1,))
      (3): ELU(alpha=1.0)
      (4): Flatten(start_dim=1, end_dim=-1)
    )
    (linear_output): Sequential(
      (0): Linear(in_features=30, out_features=16, bias=True)
      (1): ELU(alpha=1.0)
    )
  )
  (actor_teacher_backbone): MixedMlpBarlowTwinsActor(
    (mlp_encoder): Sequential(
      (0): Linear(in_features=195, out_features=512, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=512, out_features=256, bias=True)
      (3): ELU(alpha=1.0)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (5): Linear(in_features=256, out_features=128, bias=True)
      (6): ELU(alpha=1.0)
      (7): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (8): Linear(in_features=128, out_features=23, bias=True)
    )
    (actor): MixedMlp(
      (gate): Sequential(
        (0): Linear(in_features=62, out_features=128, bias=True)
        (1): ELU(alpha=1.0)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): ELU(alpha=1.0)
        (4): Linear(in_features=128, out_features=4, bias=True)
      )
    )
    (obs_encoder): Sequential(
      (0): Linear(in_features=39, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (5): Linear(in_features=128, out_features=16, bias=True)
    )
    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (critic): Sequential(
    (0): Linear(in_features=286, out_features=512, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=256, out_features=128, bias=True)
    (5): ELU(alpha=1.0)
    (6): Linear(in_features=128, out_features=1, bias=True)
  )
  (cost): Sequential(
    (0): Linear(in_features=286, out_features=512, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=256, out_features=128, bias=True)
    (5): ELU(alpha=1.0)
    (6): Linear(in_features=128, out_features=4, bias=True)
    (7): Softplus(beta=1, threshold=20)
  )
)

State Dict Shapes:
std: torch.Size([10])
history_encoder.encoder.0.weight: torch.Size([30, 39])
history_encoder.encoder.0.bias: torch.Size([30])
history_encoder.conv_layers.0.weight: torch.Size([20, 30, 4])
history_encoder.conv_layers.0.bias: torch.Size([20])
history_encoder.conv_layers.2.weight: torch.Size([10, 20, 2])
history_encoder.conv_layers.2.bias: torch.Size([10])
history_encoder.linear_output.0.weight: torch.Size([16, 30])
history_encoder.linear_output.0.bias: torch.Size([16])
actor_teacher_backbone.mlp_encoder.0.weight: torch.Size([512, 195])
actor_teacher_backbone.mlp_encoder.0.bias: torch.Size([512])
actor_teacher_backbone.mlp_encoder.2.weight: torch.Size([256, 512])
actor_teacher_backbone.mlp_encoder.2.bias: torch.Size([256])
actor_teacher_backbone.mlp_encoder.4.weight: torch.Size([256])
actor_teacher_backbone.mlp_encoder.4.bias: torch.Size([256])
actor_teacher_backbone.mlp_encoder.5.weight: torch.Size([128, 256])
actor_teacher_backbone.mlp_encoder.5.bias: torch.Size([128])
actor_teacher_backbone.mlp_encoder.7.weight: torch.Size([128])
actor_teacher_backbone.mlp_encoder.7.bias: torch.Size([128])
actor_teacher_backbone.mlp_encoder.8.weight: torch.Size([23, 128])
actor_teacher_backbone.mlp_encoder.8.bias: torch.Size([23])
actor_teacher_backbone.actor.w0: torch.Size([4, 62, 128])
actor_teacher_backbone.actor.b0: torch.Size([4, 128])
actor_teacher_backbone.actor.w1: torch.Size([4, 151, 128])
actor_teacher_backbone.actor.b1: torch.Size([4, 128])
actor_teacher_backbone.actor.w2: torch.Size([4, 151, 10])
actor_teacher_backbone.actor.b2: torch.Size([4, 10])
actor_teacher_backbone.actor.gate.0.weight: torch.Size([128, 62])
actor_teacher_backbone.actor.gate.0.bias: torch.Size([128])
actor_teacher_backbone.actor.gate.2.weight: torch.Size([128, 128])
actor_teacher_backbone.actor.gate.2.bias: torch.Size([128])
actor_teacher_backbone.actor.gate.4.weight: torch.Size([4, 128])
actor_teacher_backbone.actor.gate.4.bias: torch.Size([4])
actor_teacher_backbone.obs_encoder.0.weight: torch.Size([256, 39])
actor_teacher_backbone.obs_encoder.0.bias: torch.Size([256])
actor_teacher_backbone.obs_encoder.2.weight: torch.Size([128, 256])
actor_teacher_backbone.obs_encoder.2.bias: torch.Size([128])
actor_teacher_backbone.obs_encoder.4.weight: torch.Size([128])
actor_teacher_backbone.obs_encoder.4.bias: torch.Size([128])
actor_teacher_backbone.obs_encoder.5.weight: torch.Size([16, 128])
actor_teacher_backbone.obs_encoder.5.bias: torch.Size([16])
actor_teacher_backbone.bn.running_mean: torch.Size([16])
actor_teacher_backbone.bn.running_var: torch.Size([16])
actor_teacher_backbone.bn.num_batches_tracked: torch.Size([])
critic.0.weight: torch.Size([512, 286])
critic.0.bias: torch.Size([512])
critic.2.weight: torch.Size([256, 512])
critic.2.bias: torch.Size([256])
critic.4.weight: torch.Size([128, 256])
critic.4.bias: torch.Size([128])
critic.6.weight: torch.Size([1, 128])
critic.6.bias: torch.Size([1])
cost.0.weight: torch.Size([512, 286])
cost.0.bias: torch.Size([512])
cost.2.weight: torch.Size([256, 512])
cost.2.bias: torch.Size([256])
cost.4.weight: torch.Size([128, 256])
cost.4.bias: torch.Size([128])
cost.6.weight: torch.Size([4, 128])
cost.6.bias: torch.Size([4])
